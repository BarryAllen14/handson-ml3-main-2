{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem    \n",
    "## Xavier and He Initialization  \n",
    "  ![](handson-ml3-main/images/deep/Screenshot%202022-10-26%20142237.png)  \n",
    "\n",
    "For the uniform distribution, just use r = $âˆš3Ïƒ^{2}$. \n",
    "   \n",
    "![](handson-ml3-main/images/deep/Screenshot%202022-10-26%20142610.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation='relu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can obtain any of the initializations listed in Table 11-1\n",
    "and more using the `VarianceScaling` initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = tf.keras.initializers.variance_scaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "dense = tf.keras.layers.Dense(50, activation='relu', kernel_initializer=he_avg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions  \n",
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_relu = tf.keras.layers.LeakyReLU(alpha=.2)    # defaults to alpha=0.3\n",
    "dense = tf.keras.layers.Dense(50, activation=leaky_relu, kernel_initializer='he_normal')\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#     # [...]  # more layers\n",
    "#     tf.keras.layers.Dense(50, kernel_initializer=\"he_normal\"),  # no activation\n",
    "#     tf.keras.layers.LeakyReLU(alpha=0.2),  # activation as a separate layer\n",
    "#     # [...]  # more layers\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU\n",
    "*Outperforms all RELU variants ***but*** Computationaly Expensive*  \n",
    "Implementing `ELU` in TensorFlow is trivial, just specify the activation function when building each layer, and use `He initialization`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation='elu', kernel_initializer='he_normal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU\n",
    "Too many constraints too outperform `ELU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = tf.keras.layers.Dense(50, activation='selu', kernel_initializer='lecun_normal')  # lecun_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GELU, Swish and Mish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# extra code - clear the name counters and set the random seed\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(300, activation='swish', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(100, activation='swish', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 17s 8ms/step - loss: 0.5507 - accuracy: 0.8091 - val_loss: 0.3932 - val_accuracy: 0.8570\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.4072 - accuracy: 0.8563 - val_loss: 0.3597 - val_accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fca63b9730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds\n",
    "\n",
    "# extra code â€“ just show that the model works! ðŸ˜Š\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\",\n",
    "              metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping\n",
    "All `tf.keras.optimizers` accept `clipnorm` or `clipvalue` arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers\n",
    "### Reusing a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 1.0997 - accuracy: 0.6639 - val_loss: 0.6670 - val_accuracy: 0.7919\n",
      "Epoch 2/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.5866 - accuracy: 0.8134 - val_loss: 0.4986 - val_accuracy: 0.8350\n",
      "Epoch 3/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4768 - accuracy: 0.8483 - val_loss: 0.4297 - val_accuracy: 0.8564\n",
      "Epoch 4/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.4211 - accuracy: 0.8630 - val_loss: 0.3905 - val_accuracy: 0.8671\n",
      "Epoch 5/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.3868 - accuracy: 0.8708 - val_loss: 0.3654 - val_accuracy: 0.8732\n",
      "Epoch 6/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.3633 - accuracy: 0.8779 - val_loss: 0.3484 - val_accuracy: 0.8782\n",
      "Epoch 7/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.3464 - accuracy: 0.8818 - val_loss: 0.3331 - val_accuracy: 0.8802\n",
      "Epoch 8/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.3325 - accuracy: 0.8854 - val_loss: 0.3290 - val_accuracy: 0.8859\n",
      "Epoch 9/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.3218 - accuracy: 0.8888 - val_loss: 0.3158 - val_accuracy: 0.8887\n",
      "Epoch 10/20\n",
      "1376/1376 [==============================] - 3s 3ms/step - loss: 0.3122 - accuracy: 0.8927 - val_loss: 0.3103 - val_accuracy: 0.8920\n",
      "Epoch 11/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.3040 - accuracy: 0.8947 - val_loss: 0.3053 - val_accuracy: 0.8915\n",
      "Epoch 12/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2972 - accuracy: 0.8975 - val_loss: 0.3041 - val_accuracy: 0.8945\n",
      "Epoch 13/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.8995 - val_loss: 0.2968 - val_accuracy: 0.8952\n",
      "Epoch 14/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2858 - accuracy: 0.9014 - val_loss: 0.2893 - val_accuracy: 0.8972\n",
      "Epoch 15/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2809 - accuracy: 0.9026 - val_loss: 0.2862 - val_accuracy: 0.8992\n",
      "Epoch 16/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2763 - accuracy: 0.9049 - val_loss: 0.2846 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2720 - accuracy: 0.9049 - val_loss: 0.2799 - val_accuracy: 0.9032\n",
      "Epoch 18/20\n",
      "1376/1376 [==============================] - 4s 3ms/step - loss: 0.2675 - accuracy: 0.9074 - val_loss: 0.2830 - val_accuracy: 0.8982\n",
      "Epoch 19/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2640 - accuracy: 0.9085 - val_loss: 0.2760 - val_accuracy: 0.9047\n",
      "Epoch 20/20\n",
      "1376/1376 [==============================] - 3s 2ms/step - loss: 0.2601 - accuracy: 0.9105 - val_loss: 0.2759 - val_accuracy: 0.9030\n",
      "INFO:tensorflow:Assets written to: my_model_A\\assets\n"
     ]
    }
   ],
   "source": [
    "# extra code â€“ split Fashion MNIST into tasks A and B, then train and save\n",
    "#              model A to \"my_model_A\".\n",
    "\n",
    "pos_class_id = class_names.index(\"Pullover\")\n",
    "neg_class_id = class_names.index(\"T-shirt/top\")\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - set([neg_class_id, pos_class_id]))\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        y_A[y_A == old_class_id] = new_class_id  # reorder class ids for A\n",
    "    return ((X[~y_for_B], y_A), (X[y_for_B], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_A = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(8, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                      validation_data=(X_valid_A, y_valid_A))\n",
    "model_A.save(\"my_model_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 53ms/step - loss: 0.9635 - accuracy: 0.4350 - val_loss: 0.8553 - val_accuracy: 0.4609\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8688 - accuracy: 0.4100 - val_loss: 0.7952 - val_accuracy: 0.4164\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.8034 - accuracy: 0.3800 - val_loss: 0.7502 - val_accuracy: 0.3591\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.7522 - accuracy: 0.3450 - val_loss: 0.7223 - val_accuracy: 0.3966\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7204 - accuracy: 0.4450 - val_loss: 0.6994 - val_accuracy: 0.5064\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6934 - accuracy: 0.5300 - val_loss: 0.6797 - val_accuracy: 0.5865\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6700 - accuracy: 0.5700 - val_loss: 0.6620 - val_accuracy: 0.6469\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6509 - accuracy: 0.6900 - val_loss: 0.6456 - val_accuracy: 0.6973\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6319 - accuracy: 0.7150 - val_loss: 0.6306 - val_accuracy: 0.7428\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6147 - accuracy: 0.7800 - val_loss: 0.6164 - val_accuracy: 0.7735\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5986 - accuracy: 0.8250 - val_loss: 0.6028 - val_accuracy: 0.7933\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5833 - accuracy: 0.8600 - val_loss: 0.5892 - val_accuracy: 0.8309\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5685 - accuracy: 0.8900 - val_loss: 0.5777 - val_accuracy: 0.8447\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.5554 - accuracy: 0.9200 - val_loss: 0.5662 - val_accuracy: 0.8566\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5431 - accuracy: 0.9150 - val_loss: 0.5547 - val_accuracy: 0.8734\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.5306 - accuracy: 0.9150 - val_loss: 0.5431 - val_accuracy: 0.8843\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5184 - accuracy: 0.9300 - val_loss: 0.5326 - val_accuracy: 0.8912\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5069 - accuracy: 0.9300 - val_loss: 0.5213 - val_accuracy: 0.9041\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4952 - accuracy: 0.9300 - val_loss: 0.5108 - val_accuracy: 0.9080\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.4846 - accuracy: 0.9300 - val_loss: 0.5014 - val_accuracy: 0.9159\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.509844958782196, 0.890500009059906]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code â€“ train and evaluate model B, without reusing model A\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model_B = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "                metrics=[\"accuracy\"])\n",
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = tf.keras.models.load_model(\"my_model_A\")\n",
    "model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ ensure reproducibility\n",
    "\n",
    "model_A_clone = tf.keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "\n",
    "# extra code â€“ creating model_B_on_A just like in the previous cell\n",
    "model_B_on_A = tf.keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 53ms/step - loss: 1.1162 - accuracy: 0.2600 - val_loss: 1.0024 - val_accuracy: 0.2700\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 1.0503 - accuracy: 0.1550 - val_loss: 0.9671 - val_accuracy: 0.2117\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 1.0131 - accuracy: 0.1500 - val_loss: 0.9496 - val_accuracy: 0.1800\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.9760 - accuracy: 0.1500 - val_loss: 0.9262 - val_accuracy: 0.1978\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 1s 40ms/step - loss: 0.9138 - accuracy: 0.1650 - val_loss: 0.8080 - val_accuracy: 0.3650\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.8070 - accuracy: 0.3100 - val_loss: 0.7187 - val_accuracy: 0.4639\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.7190 - accuracy: 0.4750 - val_loss: 0.6672 - val_accuracy: 0.6192\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6416 - accuracy: 0.6650 - val_loss: 0.5989 - val_accuracy: 0.7498\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5882 - accuracy: 0.7600 - val_loss: 0.5516 - val_accuracy: 0.8259\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.5412 - accuracy: 0.8300 - val_loss: 0.5141 - val_accuracy: 0.8665\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.5020 - accuracy: 0.8600 - val_loss: 0.4916 - val_accuracy: 0.8556\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.4812 - accuracy: 0.8800 - val_loss: 0.4588 - val_accuracy: 0.8971\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4465 - accuracy: 0.8950 - val_loss: 0.4357 - val_accuracy: 0.9159\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4228 - accuracy: 0.9050 - val_loss: 0.4164 - val_accuracy: 0.9189\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.4039 - accuracy: 0.9150 - val_loss: 0.3978 - val_accuracy: 0.9228\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3837 - accuracy: 0.9150 - val_loss: 0.3821 - val_accuracy: 0.9278\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3658 - accuracy: 0.9300 - val_loss: 0.3693 - val_accuracy: 0.9268\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.3527 - accuracy: 0.9500 - val_loss: 0.3571 - val_accuracy: 0.9318\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3402 - accuracy: 0.9500 - val_loss: 0.3424 - val_accuracy: 0.9337\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.3265 - accuracy: 0.9550 - val_loss: 0.3352 - val_accuracy: 0.9347\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.9330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3391644358634949, 0.9330000281333923]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    return tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28,28]),\n",
    "    tf.keras.layers.Dense(100, activation='swish', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(100, activation='swish', kernel_initializer='he_normal'),\n",
    "    tf.keras.layers.Dense(100, activation='swish', kernel_initializer='he_normal'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "def build_and_train_model(optimizer):\n",
    "    model = build_model()\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7735 - accuracy: 0.7391 - val_loss: 0.5377 - val_accuracy: 0.8086\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5007 - accuracy: 0.8263 - val_loss: 0.4708 - val_accuracy: 0.8280\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4520 - accuracy: 0.8414 - val_loss: 0.4376 - val_accuracy: 0.8450\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4229 - accuracy: 0.8516 - val_loss: 0.3975 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3999 - accuracy: 0.8589 - val_loss: 0.3887 - val_accuracy: 0.8588\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3859 - accuracy: 0.8617 - val_loss: 0.3892 - val_accuracy: 0.8632\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3691 - accuracy: 0.8664 - val_loss: 0.3888 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3596 - accuracy: 0.8697 - val_loss: 0.3672 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3496 - accuracy: 0.8747 - val_loss: 0.3956 - val_accuracy: 0.8510\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3397 - accuracy: 0.8765 - val_loss: 0.3998 - val_accuracy: 0.8564\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "history_sgd = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7667 - accuracy: 0.7359 - val_loss: 0.5382 - val_accuracy: 0.7954\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4976 - accuracy: 0.8276 - val_loss: 0.4664 - val_accuracy: 0.8260\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4500 - accuracy: 0.8418 - val_loss: 0.4381 - val_accuracy: 0.8444\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4225 - accuracy: 0.8520 - val_loss: 0.4017 - val_accuracy: 0.8544\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3996 - accuracy: 0.8578 - val_loss: 0.3969 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3855 - accuracy: 0.8631 - val_loss: 0.4006 - val_accuracy: 0.8560\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3693 - accuracy: 0.8673 - val_loss: 0.3804 - val_accuracy: 0.8636\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3598 - accuracy: 0.8699 - val_loss: 0.3733 - val_accuracy: 0.8606\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3503 - accuracy: 0.8737 - val_loss: 0.3904 - val_accuracy: 0.8568\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3396 - accuracy: 0.8775 - val_loss: 0.3807 - val_accuracy: 0.8634\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "history_momentum = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7538 - accuracy: 0.7431 - val_loss: 0.5243 - val_accuracy: 0.8182\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4871 - accuracy: 0.8303 - val_loss: 0.4610 - val_accuracy: 0.8310\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4436 - accuracy: 0.8446 - val_loss: 0.4278 - val_accuracy: 0.8460\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.4181 - accuracy: 0.8531 - val_loss: 0.4015 - val_accuracy: 0.8548\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3985 - accuracy: 0.8580 - val_loss: 0.3857 - val_accuracy: 0.8576\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3856 - accuracy: 0.8630 - val_loss: 0.4189 - val_accuracy: 0.8524\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3711 - accuracy: 0.8673 - val_loss: 0.4180 - val_accuracy: 0.8482\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3616 - accuracy: 0.8694 - val_loss: 0.3799 - val_accuracy: 0.8600\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3523 - accuracy: 0.8747 - val_loss: 0.3773 - val_accuracy: 0.8608\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3419 - accuracy: 0.8759 - val_loss: 0.3900 - val_accuracy: 0.8600\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.9,\n",
    "                                    nesterov=True)\n",
    "\n",
    "history_momentum = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.1503 - accuracy: 0.6254 - val_loss: 0.7478 - val_accuracy: 0.7572\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.6852 - accuracy: 0.7733 - val_loss: 0.6184 - val_accuracy: 0.7972\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.5997 - accuracy: 0.7965 - val_loss: 0.5656 - val_accuracy: 0.8092\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5589 - accuracy: 0.8084 - val_loss: 0.5377 - val_accuracy: 0.8144\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5338 - accuracy: 0.8152 - val_loss: 0.5187 - val_accuracy: 0.8166\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5161 - accuracy: 0.8200 - val_loss: 0.5081 - val_accuracy: 0.8224\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5029 - accuracy: 0.8246 - val_loss: 0.4936 - val_accuracy: 0.8266\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4925 - accuracy: 0.8286 - val_loss: 0.4856 - val_accuracy: 0.8266\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4836 - accuracy: 0.8323 - val_loss: 0.4795 - val_accuracy: 0.8278\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4759 - accuracy: 0.8352 - val_loss: 0.4716 - val_accuracy: 0.8294\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.001)\n",
    "\n",
    "history_adagrad = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4960 - accuracy: 0.8211 - val_loss: 0.4427 - val_accuracy: 0.8360\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3703 - accuracy: 0.8660 - val_loss: 0.4204 - val_accuracy: 0.8408\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.8774 - val_loss: 0.3851 - val_accuracy: 0.8622\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3229 - accuracy: 0.8868 - val_loss: 0.4020 - val_accuracy: 0.8696\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3096 - accuracy: 0.8897 - val_loss: 0.3525 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3008 - accuracy: 0.8935 - val_loss: 0.3928 - val_accuracy: 0.8748\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2970 - accuracy: 0.8940 - val_loss: 0.4083 - val_accuracy: 0.8820\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2918 - accuracy: 0.8975 - val_loss: 0.4239 - val_accuracy: 0.8750\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2875 - accuracy: 0.8995 - val_loss: 0.4401 - val_accuracy: 0.8774\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2853 - accuracy: 0.9013 - val_loss: 0.4599 - val_accuracy: 0.8744\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "\n",
    "history_rmsprop = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4876 - accuracy: 0.8244 - val_loss: 0.4176 - val_accuracy: 0.8322\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3582 - accuracy: 0.8663 - val_loss: 0.3833 - val_accuracy: 0.8486\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3208 - accuracy: 0.8812 - val_loss: 0.3353 - val_accuracy: 0.8812\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2937 - accuracy: 0.8911 - val_loss: 0.3198 - val_accuracy: 0.8818\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2744 - accuracy: 0.8962 - val_loss: 0.3117 - val_accuracy: 0.8844\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2594 - accuracy: 0.9029 - val_loss: 0.3201 - val_accuracy: 0.8884\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2444 - accuracy: 0.9068 - val_loss: 0.3296 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2333 - accuracy: 0.9103 - val_loss: 0.3240 - val_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2220 - accuracy: 0.9152 - val_loss: 0.3432 - val_accuracy: 0.8862\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2131 - accuracy: 0.9187 - val_loss: 0.3536 - val_accuracy: 0.8806\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9,\n",
    "                                     beta_2=0.999)\n",
    "\n",
    "history_adam = build_and_train_model(optimizer)  # extra code                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adamax Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5353 - accuracy: 0.8105 - val_loss: 0.4584 - val_accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3967 - accuracy: 0.8575 - val_loss: 0.4093 - val_accuracy: 0.8456\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3602 - accuracy: 0.8682 - val_loss: 0.3595 - val_accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3341 - accuracy: 0.8778 - val_loss: 0.3395 - val_accuracy: 0.8744\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3138 - accuracy: 0.8837 - val_loss: 0.3284 - val_accuracy: 0.8802\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2992 - accuracy: 0.8902 - val_loss: 0.3323 - val_accuracy: 0.8804\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2855 - accuracy: 0.8939 - val_loss: 0.3340 - val_accuracy: 0.8796\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2768 - accuracy: 0.8964 - val_loss: 0.3081 - val_accuracy: 0.8882\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2660 - accuracy: 0.9011 - val_loss: 0.3275 - val_accuracy: 0.8806\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2554 - accuracy: 0.9039 - val_loss: 0.3334 - val_accuracy: 0.8772\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adamax(learning_rate=0.001, beta_1=0.9,\n",
    "                                       beta_2=0.999)\n",
    "\n",
    "history_adamax = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nadam Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4717 - accuracy: 0.8275 - val_loss: 0.3873 - val_accuracy: 0.8516\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3444 - accuracy: 0.8721 - val_loss: 0.3872 - val_accuracy: 0.8482\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3072 - accuracy: 0.8851 - val_loss: 0.3602 - val_accuracy: 0.8702\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2852 - accuracy: 0.8944 - val_loss: 0.3328 - val_accuracy: 0.8806\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2662 - accuracy: 0.8995 - val_loss: 0.3133 - val_accuracy: 0.8828\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2491 - accuracy: 0.9053 - val_loss: 0.3440 - val_accuracy: 0.8790\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2373 - accuracy: 0.9094 - val_loss: 0.3386 - val_accuracy: 0.8842\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2243 - accuracy: 0.9135 - val_loss: 0.3380 - val_accuracy: 0.8866\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2133 - accuracy: 0.9192 - val_loss: 0.3350 - val_accuracy: 0.8868\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2042 - accuracy: 0.9229 - val_loss: 0.3634 - val_accuracy: 0.8862\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9,\n",
    "                                      beta_2=0.999)\n",
    "\n",
    "history_nadam = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdamW Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4827 - accuracy: 0.8253 - val_loss: 0.4048 - val_accuracy: 0.8372\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3553 - accuracy: 0.8684 - val_loss: 0.3845 - val_accuracy: 0.8538\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3183 - accuracy: 0.8810 - val_loss: 0.3334 - val_accuracy: 0.8768\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2927 - accuracy: 0.8919 - val_loss: 0.3293 - val_accuracy: 0.8788\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2725 - accuracy: 0.8978 - val_loss: 0.3199 - val_accuracy: 0.8808\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2582 - accuracy: 0.9017 - val_loss: 0.3270 - val_accuracy: 0.8828\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2454 - accuracy: 0.9066 - val_loss: 0.3489 - val_accuracy: 0.8808\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2339 - accuracy: 0.9107 - val_loss: 0.3335 - val_accuracy: 0.8876\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2237 - accuracy: 0.9148 - val_loss: 0.3353 - val_accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.2144 - accuracy: 0.9189 - val_loss: 0.3946 - val_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(weight_decay=1e-5, learning_rate=0.001,\n",
    "                                 beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "\n",
    "history_adamw = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling\n",
    "### Power Scheduling\n",
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* Keras uses `c=1` and `s = 1 / decay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5524 - accuracy: 0.8025 - val_loss: 0.4922 - val_accuracy: 0.8182\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4474 - accuracy: 0.8433 - val_loss: 0.4820 - val_accuracy: 0.8300\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4190 - accuracy: 0.8533 - val_loss: 0.4455 - val_accuracy: 0.8472\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4116 - accuracy: 0.8592 - val_loss: 0.3992 - val_accuracy: 0.8630\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3968 - accuracy: 0.8633 - val_loss: 0.4219 - val_accuracy: 0.8582\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4095 - accuracy: 0.8628 - val_loss: 0.4838 - val_accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3974 - accuracy: 0.8648 - val_loss: 0.4767 - val_accuracy: 0.8432\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3898 - accuracy: 0.8663 - val_loss: 0.4249 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3827 - accuracy: 0.8690 - val_loss: 0.4034 - val_accuracy: 0.8638\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.3716 - accuracy: 0.8716 - val_loss: 0.4347 - val_accuracy: 0.8584\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, decay=1e-4, beta_1=0.9,\n",
    "                                      beta_2=0.999)\n",
    "\n",
    "history_power_scheduling = build_and_train_model(optimizer)  # extra code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling\n",
    "```lr = lr0 * 0.1 ** (epoch / s)```  \n",
    "* Learning rate will gradually\n",
    "drop by a factor of 10 every s steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5582 - accuracy: 0.8013 - val_loss: 0.4763 - val_accuracy: 0.8208 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4354 - accuracy: 0.8478 - val_loss: 0.4465 - val_accuracy: 0.8356 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3927 - accuracy: 0.8574 - val_loss: 0.4396 - val_accuracy: 0.8482 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8675 - val_loss: 0.4126 - val_accuracy: 0.8530 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3568 - accuracy: 0.8725 - val_loss: 0.3929 - val_accuracy: 0.8658 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3437 - accuracy: 0.8762 - val_loss: 0.4161 - val_accuracy: 0.8538 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.3283 - accuracy: 0.8811 - val_loss: 0.4031 - val_accuracy: 0.8592 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.3202 - accuracy: 0.8851 - val_loss: 0.3713 - val_accuracy: 0.8664 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3052 - accuracy: 0.8882 - val_loss: 0.3688 - val_accuracy: 0.8684 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2951 - accuracy: 0.8909 - val_loss: 0.3527 - val_accuracy: 0.8774 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2840 - accuracy: 0.8950 - val_loss: 0.3671 - val_accuracy: 0.8758 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2767 - accuracy: 0.8969 - val_loss: 0.3787 - val_accuracy: 0.8694 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2691 - accuracy: 0.8990 - val_loss: 0.3541 - val_accuracy: 0.8776 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2610 - accuracy: 0.9028 - val_loss: 0.3715 - val_accuracy: 0.8798 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2528 - accuracy: 0.9043 - val_loss: 0.3633 - val_accuracy: 0.8786 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9054 - val_loss: 0.3687 - val_accuracy: 0.8772 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2406 - accuracy: 0.9081 - val_loss: 0.3965 - val_accuracy: 0.8744 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2363 - accuracy: 0.9104 - val_loss: 0.3944 - val_accuracy: 0.8746 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2307 - accuracy: 0.9120 - val_loss: 0.3802 - val_accuracy: 0.8774 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9136 - val_loss: 0.3968 - val_accuracy: 0.8772 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2208 - accuracy: 0.9155 - val_loss: 0.3984 - val_accuracy: 0.8782 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2160 - accuracy: 0.9171 - val_loss: 0.4169 - val_accuracy: 0.8748 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.2124 - accuracy: 0.9183 - val_loss: 0.4186 - val_accuracy: 0.8790 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2088 - accuracy: 0.9195 - val_loss: 0.4259 - val_accuracy: 0.8790 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.2054 - accuracy: 0.9204 - val_loss: 0.4474 - val_accuracy: 0.8762 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1 ** (epoch / 20)\n",
    "\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)\n",
    "\n",
    "# extra code â€“ build and compile a model for Fashion MNIST\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9,\n",
    "                                      beta_2=0.999)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train, y_train, epochs=25,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Constant Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Scheduling  \n",
    "Measure the validation error every N steps (just like for early stopping),\n",
    "and reduce the learning rate by a factor of . when the error stops\n",
    "dropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7709 - accuracy: 0.7372 - val_loss: 0.5242 - val_accuracy: 0.8174 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5045 - accuracy: 0.8249 - val_loss: 0.4786 - val_accuracy: 0.8242 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4480 - accuracy: 0.8417 - val_loss: 0.4395 - val_accuracy: 0.8416 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4200 - accuracy: 0.8507 - val_loss: 0.4030 - val_accuracy: 0.8512 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3993 - accuracy: 0.8572 - val_loss: 0.3964 - val_accuracy: 0.8542 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3820 - accuracy: 0.8628 - val_loss: 0.4041 - val_accuracy: 0.8568 - lr: 0.0100\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3707 - accuracy: 0.8653 - val_loss: 0.3813 - val_accuracy: 0.8632 - lr: 0.0100\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3591 - accuracy: 0.8700 - val_loss: 0.3741 - val_accuracy: 0.8582 - lr: 0.0100\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3495 - accuracy: 0.8739 - val_loss: 0.3621 - val_accuracy: 0.8658 - lr: 0.0100\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3405 - accuracy: 0.8763 - val_loss: 0.3637 - val_accuracy: 0.8634 - lr: 0.0100\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3334 - accuracy: 0.8782 - val_loss: 0.3591 - val_accuracy: 0.8668 - lr: 0.0100\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3264 - accuracy: 0.8806 - val_loss: 0.3556 - val_accuracy: 0.8674 - lr: 0.0100\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3207 - accuracy: 0.8827 - val_loss: 0.3458 - val_accuracy: 0.8726 - lr: 0.0100\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3138 - accuracy: 0.8847 - val_loss: 0.3613 - val_accuracy: 0.8702 - lr: 0.0100\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3085 - accuracy: 0.8876 - val_loss: 0.3501 - val_accuracy: 0.8746 - lr: 0.0100\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3027 - accuracy: 0.8896 - val_loss: 0.3370 - val_accuracy: 0.8726 - lr: 0.0100\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2986 - accuracy: 0.8893 - val_loss: 0.3527 - val_accuracy: 0.8676 - lr: 0.0100\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2930 - accuracy: 0.8922 - val_loss: 0.3434 - val_accuracy: 0.8736 - lr: 0.0100\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2894 - accuracy: 0.8931 - val_loss: 0.3834 - val_accuracy: 0.8510 - lr: 0.0100\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2855 - accuracy: 0.8946 - val_loss: 0.3328 - val_accuracy: 0.8736 - lr: 0.0100\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2806 - accuracy: 0.8968 - val_loss: 0.3300 - val_accuracy: 0.8748 - lr: 0.0100\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2762 - accuracy: 0.8981 - val_loss: 0.3270 - val_accuracy: 0.8776 - lr: 0.0100\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2733 - accuracy: 0.8991 - val_loss: 0.3408 - val_accuracy: 0.8716 - lr: 0.0100\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2683 - accuracy: 0.9014 - val_loss: 0.3317 - val_accuracy: 0.8762 - lr: 0.0100\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2658 - accuracy: 0.9024 - val_loss: 0.3364 - val_accuracy: 0.8778 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "# extra code â€“ build and compile the model\n",
    "\n",
    "lr0 = 0.01\n",
    "model = build_model()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history = model.fit(X_train, y_train, epochs=25,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras schedulers\n",
    "Updates the learning rate at each step rather\n",
    "than at each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.7670 - accuracy: 0.7398 - val_loss: 0.5221 - val_accuracy: 0.8212\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.5071 - accuracy: 0.8219 - val_loss: 0.4849 - val_accuracy: 0.8256\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4528 - accuracy: 0.8396 - val_loss: 0.4472 - val_accuracy: 0.8430\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4264 - accuracy: 0.8496 - val_loss: 0.4131 - val_accuracy: 0.8580\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4060 - accuracy: 0.8559 - val_loss: 0.4031 - val_accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3904 - accuracy: 0.8617 - val_loss: 0.4148 - val_accuracy: 0.8566\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3796 - accuracy: 0.8647 - val_loss: 0.3900 - val_accuracy: 0.8630\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3698 - accuracy: 0.8683 - val_loss: 0.3903 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3613 - accuracy: 0.8716 - val_loss: 0.3714 - val_accuracy: 0.8668\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3539 - accuracy: 0.8733 - val_loss: 0.3744 - val_accuracy: 0.8674\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "n_steps = n_epochs * math.ceil(len(X_train) / batch_size)\n",
    "scheduled_learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01, decay_steps=n_steps, decay_rate=0.1)\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=scheduled_learning_rate)\n",
    "\n",
    "# extra code â€“ build and train the model\n",
    "model = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code â€“ shows how to use PiecewiseConstantDecay\n",
    "# scheduled_learning_rate = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "#     values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization\n",
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Dense(100, activation=\"relu\",\n",
    "                              kernel_initializer=\"he_normal\",\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or use `l1(0.1)` for â„“<sub>1</sub> regularization with a factor of 0.1, or `l1_l2(0.1, 0.01)` for both â„“<sub>1</sub> and â„“<sub>2</sub> regularization, with factors 0.1 and 0.01 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random.set_seed(42)  # extra code â€“ for reproducibility\n",
    "\n",
    "# from functools import partial\n",
    "\n",
    "# RegularizedDense = partial(tf.keras.layers.Dense,\n",
    "#                            activation=\"relu\",\n",
    "#                            kernel_initializer=\"he_normal\",\n",
    "#                            kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "#     RegularizedDense(100),\n",
    "#     RegularizedDense(100),\n",
    "#     RegularizedDense(10, activation=\"softmax\")\n",
    "# ])\n",
    "\n",
    "# # extra code â€“ compile and train the model\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.02)\n",
    "# model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "#               metrics=[\"accuracy\"])\n",
    "# history = model.fit(X_train, y_train, epochs=2,\n",
    "#                     validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.7058 - accuracy: 0.7484 - val_loss: 0.5415 - val_accuracy: 0.8158\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6395 - accuracy: 0.7785 - val_loss: 0.4800 - val_accuracy: 0.8286\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6201 - accuracy: 0.7861 - val_loss: 0.4804 - val_accuracy: 0.8290\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6133 - accuracy: 0.7854 - val_loss: 0.5043 - val_accuracy: 0.8230\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6184 - accuracy: 0.7868 - val_loss: 0.5461 - val_accuracy: 0.8336\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6329 - accuracy: 0.7812 - val_loss: 0.4977 - val_accuracy: 0.8230\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6374 - accuracy: 0.7831 - val_loss: 0.5090 - val_accuracy: 0.8344\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6487 - accuracy: 0.7780 - val_loss: 0.5250 - val_accuracy: 0.8218\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6482 - accuracy: 0.7804 - val_loss: 0.5625 - val_accuracy: 0.8346\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.6706 - accuracy: 0.7737 - val_loss: 0.5124 - val_accuracy: 0.8274\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ for reproducibility\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"swish\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(100, activation=\"swish\",\n",
    "                          kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# extra code â€“ compile and train the model\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4693 - accuracy: 0.8342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4692531228065491, 0.8342182040214539]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.8201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5206251740455627, 0.8201000094413757]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.076, 0.   , 0.235, 0.   ,\n",
       "        0.689]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code â€“ for reproducibility\n",
    "\n",
    "y_probas = np.stack([model(X_test, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "\n",
    "model.predict(X_test[:1]).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.004, 0.001, 0.001, 0.005, 0.003, 0.111, 0.004, 0.229, 0.003,\n",
       "       0.638], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.022, 0.008, 0.008, 0.031, 0.019, 0.141, 0.021, 0.241, 0.014,\n",
       "       0.267], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "y_std[0].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8302"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=1)\n",
    "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(tf.keras.layers.Dropout):\n",
    "    def call(self, inputs, training=None):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "# extra code â€“ shows how to convert Dropout to MCDropout in a Sequential model\n",
    "Dropout = tf.keras.layers.Dropout\n",
    "mc_model = tf.keras.Sequential([\n",
    "    MCDropout(layer.rate) if isinstance(layer, Dropout) else layer\n",
    "    for layer in model.layers\n",
    "])\n",
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_19 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " mc_dropout (MCDropout)      (None, 784)               0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 100)               78500     \n",
      "                                                                 \n",
      " mc_dropout_1 (MCDropout)    (None, 100)               0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " mc_dropout_2 (MCDropout)    (None, 100)               0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.25, 0.  , 0.6 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code â€“ shows that the model works without retraining\n",
    "tf.random.set_seed(42)\n",
    "np.mean([mc_model.predict(X_test[:1])\n",
    "         for sample in range(100)], axis=0).round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32ea8bee040c0262fda3837df9bb0dbef9f2bbaf3c67025b7197e1c5d673cff9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
