{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Perceptron` is equivalent to a `SGDClassifier` with `loss=\"perceptron\"`, no regularization, and a constant learning rate equal to 1:\n",
    "  \n",
    "When the Perceptron finds a decision boundary that properly separates the classes, it stops learning. This means that the decision boundary is often quite close to one class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# as_frame : If True, the data is a pandas DataFrame including columns with appropriate dtypes (numeric).\n",
    "# The target is a pandas DataFrame or Series depending on the number of target columns. \n",
    "iris = load_iris(as_frame=True)\n",
    "X = iris.data[[\"petal length (cm)\", \"petal width (cm)\"]].values\n",
    "y = iris.target == 0    # Iris setosa\n",
    "\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "X_new = [[2, 0.5], [3, 1]]\n",
    "y_pred = per_clf.predict(X_new)  # predicts True and False for these 2 flowers\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053326657968451"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification MLPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code – this was left as an exercise for the reader\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], max_iter=10_000,\n",
    "                        random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_valid, y_valid)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing MLPs with Keras\n",
    "## Building an Image Classifier Using the Sequential API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(55000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "fashion_minst = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_minst\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "print(X_train.dtype)\n",
    "print(X_train.shape)\n",
    "\n",
    "# scale the pixel intensities down to the 0-1 range and convert them to floats, by dividing by 255:\n",
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tf.random.set_seed(42)\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.InputLayer(input_shape=[28, 28]))\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.Dense(300, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(100, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(10, activation='sodtmax'))\n",
    "\n",
    "# # extra code – clear the session to reset the name counters\n",
    "# tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    tf.keras.layers.Dense(300, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# extra code – another way to display the model's architecture\n",
    "tf.keras.utils.plot_model(model, \"my_fashion_mnist_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.reshaping.flatten.Flatten object at 0x000002018614C760>, <keras.layers.core.dense.Dense object at 0x00000201F49C1C40>, <keras.layers.core.dense.Dense object at 0x00000201F49C1F10>, <keras.layers.core.dense.Dense object at 0x00000201F49C1280>]\n",
      "dense\n",
      "[[-0.03593194 -0.03054157 -0.0151444  ...  0.06530553  0.0692066\n",
      "   0.03545918]\n",
      " [-0.03600795  0.02913261  0.07103787 ...  0.03560663  0.0585812\n",
      "  -0.04698234]\n",
      " [-0.00252919  0.06595312 -0.05073933 ... -0.00796212 -0.04944368\n",
      "   0.07376117]\n",
      " ...\n",
      " [-0.05240785  0.02755237  0.05243734 ...  0.02979355 -0.0331187\n",
      "  -0.06194266]\n",
      " [-0.03699806  0.04478769 -0.021535   ... -0.01672903 -0.0015021\n",
      "   0.05672602]\n",
      " [-0.03019015 -0.01528448  0.00533719 ... -0.01368451 -0.00535827\n",
      "  -0.07312433]]\n",
      "(784, 300)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(model.layers)\n",
    "hidden1 = model.layers[1]\n",
    "print(hidden1.name)\n",
    "\n",
    "model.get_layer('dense') is hidden1\n",
    "\n",
    "weights, biases = hidden1.get_weights()\n",
    "print(weights)\n",
    "print(weights.shape)\n",
    "print(biases)\n",
    "print(biases.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer='sgd',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# extra code – this cell is equivalent to the previous cell\n",
    "# model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#               optimizer=tf.keras.optimizers.SGD(),\n",
    "#               metrics=[tf.keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.7241 - accuracy: 0.7615 - val_loss: 0.5095 - val_accuracy: 0.8252\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4894 - accuracy: 0.8298 - val_loss: 0.4632 - val_accuracy: 0.8318\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4431 - accuracy: 0.8440 - val_loss: 0.4289 - val_accuracy: 0.8498\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4181 - accuracy: 0.8543 - val_loss: 0.4024 - val_accuracy: 0.8606\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3968 - accuracy: 0.8611 - val_loss: 0.3948 - val_accuracy: 0.8602\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3799 - accuracy: 0.8653 - val_loss: 0.3951 - val_accuracy: 0.8612\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3671 - accuracy: 0.8701 - val_loss: 0.3760 - val_accuracy: 0.8692\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3555 - accuracy: 0.8744 - val_loss: 0.3771 - val_accuracy: 0.8614\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 9s 6ms/step - loss: 0.3448 - accuracy: 0.8787 - val_loss: 0.3507 - val_accuracy: 0.8748\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.3345 - accuracy: 0.8808 - val_loss: 0.3526 - val_accuracy: 0.8744\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3258 - accuracy: 0.8840 - val_loss: 0.3650 - val_accuracy: 0.8646\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3176 - accuracy: 0.8871 - val_loss: 0.3472 - val_accuracy: 0.8692\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3104 - accuracy: 0.8899 - val_loss: 0.3304 - val_accuracy: 0.8800\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3033 - accuracy: 0.8913 - val_loss: 0.3370 - val_accuracy: 0.8770\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2969 - accuracy: 0.8945 - val_loss: 0.3343 - val_accuracy: 0.8780\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2897 - accuracy: 0.8961 - val_loss: 0.3289 - val_accuracy: 0.8778\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2847 - accuracy: 0.8963 - val_loss: 0.3391 - val_accuracy: 0.8738\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2787 - accuracy: 0.9003 - val_loss: 0.3248 - val_accuracy: 0.8828\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2734 - accuracy: 0.9024 - val_loss: 0.3469 - val_accuracy: 0.8702\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2680 - accuracy: 0.9046 - val_loss: 0.3225 - val_accuracy: 0.8780\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2631 - accuracy: 0.9056 - val_loss: 0.3144 - val_accuracy: 0.8800\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2583 - accuracy: 0.9068 - val_loss: 0.3172 - val_accuracy: 0.8824\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2535 - accuracy: 0.9095 - val_loss: 0.3446 - val_accuracy: 0.8716\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2484 - accuracy: 0.9118 - val_loss: 0.3205 - val_accuracy: 0.8824\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2442 - accuracy: 0.9117 - val_loss: 0.3193 - val_accuracy: 0.8806\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2405 - accuracy: 0.9141 - val_loss: 0.3105 - val_accuracy: 0.8826\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2355 - accuracy: 0.9144 - val_loss: 0.3188 - val_accuracy: 0.8864\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2323 - accuracy: 0.9174 - val_loss: 0.3094 - val_accuracy: 0.8890\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2284 - accuracy: 0.9177 - val_loss: 0.3136 - val_accuracy: 0.8826\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2246 - accuracy: 0.9201 - val_loss: 0.3092 - val_accuracy: 0.8858\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 30, 'steps': 1719}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.params)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(\n",
    "    figsize=(8, 5), xlim=[0, 29], ylim=[0, 1], grid=True, xlabel=\"Epoch\",\n",
    "    style=[\"r--\", \"r--.\", \"b-\", \"b-*\"])\n",
    "plt.legend(loc=\"lower left\")  # extra code\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32270267605781555, 0.883400022983551]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 353ms/step\n",
      "[[0.   0.   0.   0.   0.   0.01 0.   0.04 0.   0.96]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "[9 2 1]\n",
      "[9 2 1]\n"
     ]
    }
   ],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "print(y_proba.round(2))\n",
    "\n",
    "y_pred = y_proba.argmax(axis=-1)\n",
    "print(y_pred)\n",
    "\n",
    "np.array(class_names)[y_pred]\n",
    "\n",
    "y_new = y_test[:3]\n",
    "print(y_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Regression MLP Using the Sequential API\n",
    "we’re using a `Normalization layer` as the\n",
    "first layer: it does the same thing as Scikit-Learn’s StandardScaler, but\n",
    "it must be fitted to the training data using its `adapt() method` before you\n",
    "call the model’s `fit() method`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 6ms/step - loss: 0.8428 - root_mean_squared_error: 0.9180 - val_loss: 0.6089 - val_root_mean_squared_error: 0.7803\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3838 - root_mean_squared_error: 0.6195 - val_loss: 1.6744 - val_root_mean_squared_error: 1.2940\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3671 - root_mean_squared_error: 0.6059 - val_loss: 0.6570 - val_root_mean_squared_error: 0.8105\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3494 - root_mean_squared_error: 0.5911 - val_loss: 1.6411 - val_root_mean_squared_error: 1.2811\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3385 - root_mean_squared_error: 0.5818 - val_loss: 2.3681 - val_root_mean_squared_error: 1.5389\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3431 - root_mean_squared_error: 0.5858 - val_loss: 0.3947 - val_root_mean_squared_error: 0.6283\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3150 - root_mean_squared_error: 0.5613 - val_loss: 0.6080 - val_root_mean_squared_error: 0.7798\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3096 - root_mean_squared_error: 0.5564 - val_loss: 2.0438 - val_root_mean_squared_error: 1.4296\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3104 - root_mean_squared_error: 0.5571 - val_loss: 1.4461 - val_root_mean_squared_error: 1.2026\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3069 - root_mean_squared_error: 0.5540 - val_loss: 0.3038 - val_root_mean_squared_error: 0.5512\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2907 - root_mean_squared_error: 0.5391 - val_loss: 0.2949 - val_root_mean_squared_error: 0.5431\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2946 - root_mean_squared_error: 0.5428 - val_loss: 0.5514 - val_root_mean_squared_error: 0.7426\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.2872 - root_mean_squared_error: 0.5359 - val_loss: 0.3724 - val_root_mean_squared_error: 0.6102\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2862 - root_mean_squared_error: 0.5350 - val_loss: 0.4051 - val_root_mean_squared_error: 0.6365\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2833 - root_mean_squared_error: 0.5323 - val_loss: 0.2703 - val_root_mean_squared_error: 0.5199\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2800 - root_mean_squared_error: 0.5292 - val_loss: 0.2740 - val_root_mean_squared_error: 0.5235\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2778 - root_mean_squared_error: 0.5271 - val_loss: 0.6102 - val_root_mean_squared_error: 0.7811\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2746 - root_mean_squared_error: 0.5240 - val_loss: 0.2903 - val_root_mean_squared_error: 0.5388\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2722 - root_mean_squared_error: 0.5217 - val_loss: 0.4142 - val_root_mean_squared_error: 0.6436\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2740 - root_mean_squared_error: 0.5234 - val_loss: 0.2728 - val_root_mean_squared_error: 0.5223\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.2844 - root_mean_squared_error: 0.5333\n",
      "1/1 [==============================] - 0s 353ms/step\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['RootMeanSquaredError'])\n",
    "norm_layer.adapt(X_train)\n",
    "model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5333039164543152\n",
      "[[0.48236302]\n",
      " [1.1459419 ]\n",
      " [4.9248605 ]]\n"
     ]
    }
   ],
   "source": [
    "print(rmse_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " normalization (Normalization)  (None, 8)            17          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           270         ['normalization[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,256\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 17\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# extra code – reset the name counters and make the code reproducible\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# normalization_layer = tf.keras.layers.Normalization()\n",
    "# hidden_layer1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "# hidden_layer2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "# concat_layer = tf.keras.layers.Concatenate()\n",
    "# output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "# input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "# normalized = normalization_layer(input_)\n",
    "# hidden1 = hidden_layer1(normalized)\n",
    "# hidden2 = hidden_layer2(hidden1)\n",
    "# concat = concat_layer([input_, hidden2])\n",
    "# output = output_layer(concat)\n",
    "\n",
    "# model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "normalization_layer = tf.keras.layers.Normalization()\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:])\n",
    "normalized = normalization_layer(input_)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation='relu') (normalized)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation='relu') (hidden1)\n",
    "concat = tf.keras.layers.concatenate([input_, hidden2])\n",
    "output = tf.keras.layers.Dense(1) (concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 7ms/step - loss: 83592.1250 - root_mean_squared_error: 289.1230 - val_loss: 33864.4766 - val_root_mean_squared_error: 184.0230\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 1792.4393 - root_mean_squared_error: 42.3372 - val_loss: 23233.6270 - val_root_mean_squared_error: 152.4258\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 514.9739 - root_mean_squared_error: 22.6930 - val_loss: 14649.7236 - val_root_mean_squared_error: 121.0360\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 232.6661 - root_mean_squared_error: 15.2534 - val_loss: 8693.0186 - val_root_mean_squared_error: 93.2364\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 134.9413 - root_mean_squared_error: 11.6164 - val_loss: 5509.5273 - val_root_mean_squared_error: 74.2262\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 80.3776 - root_mean_squared_error: 8.9654 - val_loss: 3616.3525 - val_root_mean_squared_error: 60.1361\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 45.4666 - root_mean_squared_error: 6.7429 - val_loss: 2237.8721 - val_root_mean_squared_error: 47.3062\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 24.1165 - root_mean_squared_error: 4.9109 - val_loss: 1194.9037 - val_root_mean_squared_error: 34.5674\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 12.6828 - root_mean_squared_error: 3.5613 - val_loss: 710.2790 - val_root_mean_squared_error: 26.6511\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 7.5371 - root_mean_squared_error: 2.7454 - val_loss: 471.9864 - val_root_mean_squared_error: 21.7252\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 5.0151 - root_mean_squared_error: 2.2394 - val_loss: 385.8012 - val_root_mean_squared_error: 19.6418\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 3.7045 - root_mean_squared_error: 1.9247 - val_loss: 326.0929 - val_root_mean_squared_error: 18.0580\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 2.8391 - root_mean_squared_error: 1.6849 - val_loss: 328.9086 - val_root_mean_squared_error: 18.1358\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 2.2232 - root_mean_squared_error: 1.4910 - val_loss: 331.2306 - val_root_mean_squared_error: 18.1997\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 1.8072 - root_mean_squared_error: 1.3443 - val_loss: 333.5255 - val_root_mean_squared_error: 18.2627\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 1.5646 - root_mean_squared_error: 1.2509 - val_loss: 262.9916 - val_root_mean_squared_error: 16.2170\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.3563 - root_mean_squared_error: 1.1646 - val_loss: 386.1895 - val_root_mean_squared_error: 19.6517\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.2252 - root_mean_squared_error: 1.1069 - val_loss: 232.1159 - val_root_mean_squared_error: 15.2353\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 1.0612 - root_mean_squared_error: 1.0301 - val_loss: 320.6320 - val_root_mean_squared_error: 17.9062\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 1.3629 - root_mean_squared_error: 1.1674 - val_loss: 188.8842 - val_root_mean_squared_error: 13.7435\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.9965 - root_mean_squared_error: 0.9982\n",
      "1/1 [==============================] - 0s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics='RootMeanSquaredError')\n",
    "normalization_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 4s 7ms/step - loss: 1.5623 - root_mean_squared_error: 1.2499 - val_loss: 0.6583 - val_root_mean_squared_error: 0.8113\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5645 - root_mean_squared_error: 0.7513 - val_loss: 1.2844 - val_root_mean_squared_error: 1.1333\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4753 - root_mean_squared_error: 0.6894 - val_loss: 0.4516 - val_root_mean_squared_error: 0.6720\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.4266 - root_mean_squared_error: 0.6532 - val_loss: 0.5466 - val_root_mean_squared_error: 0.7393\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4046 - root_mean_squared_error: 0.6361 - val_loss: 1.1887 - val_root_mean_squared_error: 1.0903\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3907 - root_mean_squared_error: 0.6251 - val_loss: 1.6901 - val_root_mean_squared_error: 1.3001\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3869 - root_mean_squared_error: 0.6220 - val_loss: 1.7728 - val_root_mean_squared_error: 1.3315\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3677 - root_mean_squared_error: 0.6064 - val_loss: 4.8772 - val_root_mean_squared_error: 2.2084\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3734 - root_mean_squared_error: 0.6111 - val_loss: 4.7629 - val_root_mean_squared_error: 2.1824\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3915 - root_mean_squared_error: 0.6257 - val_loss: 1.5746 - val_root_mean_squared_error: 1.2548\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3535 - root_mean_squared_error: 0.5945 - val_loss: 0.3274 - val_root_mean_squared_error: 0.5722\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3485 - root_mean_squared_error: 0.5903 - val_loss: 0.5486 - val_root_mean_squared_error: 0.7407\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3430 - root_mean_squared_error: 0.5857 - val_loss: 0.3478 - val_root_mean_squared_error: 0.5898\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3378 - root_mean_squared_error: 0.5812 - val_loss: 0.3178 - val_root_mean_squared_error: 0.5638\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3368 - root_mean_squared_error: 0.5803 - val_loss: 0.3800 - val_root_mean_squared_error: 0.6164\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3297 - root_mean_squared_error: 0.5742 - val_loss: 0.3132 - val_root_mean_squared_error: 0.5596\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3300 - root_mean_squared_error: 0.5745 - val_loss: 0.3277 - val_root_mean_squared_error: 0.5724\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3262 - root_mean_squared_error: 0.5712 - val_loss: 0.4329 - val_root_mean_squared_error: 0.6580\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3236 - root_mean_squared_error: 0.5689 - val_loss: 0.8060 - val_root_mean_squared_error: 0.8977\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3319 - root_mean_squared_error: 0.5761 - val_loss: 3.3306 - val_root_mean_squared_error: 1.8250\n",
      "162/162 [==============================] - 1s 3ms/step - loss: 0.3347 - root_mean_squared_error: 0.5785\n",
      "1/1 [==============================] - 0s 111ms/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)  # extra code\n",
    "\n",
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep], outputs=[output])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "X_train_wide, X_train_deep = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_wide, X_valid_deep = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_wide, X_test_deep = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_wide, X_new_deep = X_test_wide[:3], X_test_deep[:3]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit((X_train_wide, X_train_deep), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_wide, X_valid_deep), y_valid))\n",
    "mse_test = model.evaluate((X_test_wide, X_test_deep), y_test)\n",
    "y_pred = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 5s 8ms/step - loss: 1.3557 - dense_2_loss: 1.2931 - dense_3_loss: 1.9190 - dense_2_root_mean_squared_error: 1.1371 - dense_3_root_mean_squared_error: 1.3853 - val_loss: 0.6610 - val_dense_2_loss: 0.5742 - val_dense_3_loss: 1.4416 - val_dense_2_root_mean_squared_error: 0.7578 - val_dense_3_root_mean_squared_error: 1.2007\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5184 - dense_2_loss: 0.4923 - dense_3_loss: 0.7527 - dense_2_root_mean_squared_error: 0.7017 - dense_3_root_mean_squared_error: 0.8676 - val_loss: 0.6083 - val_dense_2_loss: 0.6036 - val_dense_3_loss: 0.6501 - val_dense_2_root_mean_squared_error: 0.7769 - val_dense_3_root_mean_squared_error: 0.8063\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4510 - dense_2_loss: 0.4338 - dense_3_loss: 0.6061 - dense_2_root_mean_squared_error: 0.6586 - dense_3_root_mean_squared_error: 0.7785 - val_loss: 0.4542 - val_dense_2_loss: 0.4372 - val_dense_3_loss: 0.6076 - val_dense_2_root_mean_squared_error: 0.6612 - val_dense_3_root_mean_squared_error: 0.7795\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4198 - dense_2_loss: 0.4037 - dense_3_loss: 0.5651 - dense_2_root_mean_squared_error: 0.6354 - dense_3_root_mean_squared_error: 0.7517 - val_loss: 0.5466 - val_dense_2_loss: 0.5337 - val_dense_3_loss: 0.6620 - val_dense_2_root_mean_squared_error: 0.7306 - val_dense_3_root_mean_squared_error: 0.8136\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4103 - dense_2_loss: 0.3959 - dense_3_loss: 0.5394 - dense_2_root_mean_squared_error: 0.6292 - dense_3_root_mean_squared_error: 0.7345 - val_loss: 1.0507 - val_dense_2_loss: 1.0668 - val_dense_3_loss: 0.9062 - val_dense_2_root_mean_squared_error: 1.0328 - val_dense_3_root_mean_squared_error: 0.9519\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3993 - dense_2_loss: 0.3854 - dense_3_loss: 0.5244 - dense_2_root_mean_squared_error: 0.6208 - dense_3_root_mean_squared_error: 0.7241 - val_loss: 0.8246 - val_dense_2_loss: 0.8285 - val_dense_3_loss: 0.7891 - val_dense_2_root_mean_squared_error: 0.9102 - val_dense_3_root_mean_squared_error: 0.8883\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3899 - dense_2_loss: 0.3774 - dense_3_loss: 0.5030 - dense_2_root_mean_squared_error: 0.6143 - dense_3_root_mean_squared_error: 0.7093 - val_loss: 0.9944 - val_dense_2_loss: 0.9879 - val_dense_3_loss: 1.0527 - val_dense_2_root_mean_squared_error: 0.9939 - val_dense_3_root_mean_squared_error: 1.0260\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3813 - dense_2_loss: 0.3696 - dense_3_loss: 0.4863 - dense_2_root_mean_squared_error: 0.6080 - dense_3_root_mean_squared_error: 0.6974 - val_loss: 2.8024 - val_dense_2_loss: 2.8268 - val_dense_3_loss: 2.5823 - val_dense_2_root_mean_squared_error: 1.6813 - val_dense_3_root_mean_squared_error: 1.6069\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3811 - dense_2_loss: 0.3702 - dense_3_loss: 0.4787 - dense_2_root_mean_squared_error: 0.6084 - dense_3_root_mean_squared_error: 0.6919 - val_loss: 2.1789 - val_dense_2_loss: 2.2740 - val_dense_3_loss: 1.3232 - val_dense_2_root_mean_squared_error: 1.5080 - val_dense_3_root_mean_squared_error: 1.1503\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3825 - dense_2_loss: 0.3734 - dense_3_loss: 0.4648 - dense_2_root_mean_squared_error: 0.6110 - dense_3_root_mean_squared_error: 0.6817 - val_loss: 0.7622 - val_dense_2_loss: 0.7577 - val_dense_3_loss: 0.8022 - val_dense_2_root_mean_squared_error: 0.8705 - val_dense_3_root_mean_squared_error: 0.8956\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3625 - dense_2_loss: 0.3533 - dense_3_loss: 0.4455 - dense_2_root_mean_squared_error: 0.5944 - dense_3_root_mean_squared_error: 0.6675 - val_loss: 0.4414 - val_dense_2_loss: 0.4312 - val_dense_3_loss: 0.5333 - val_dense_2_root_mean_squared_error: 0.6566 - val_dense_3_root_mean_squared_error: 0.7303\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3629 - dense_2_loss: 0.3540 - dense_3_loss: 0.4430 - dense_2_root_mean_squared_error: 0.5950 - dense_3_root_mean_squared_error: 0.6656 - val_loss: 0.3888 - val_dense_2_loss: 0.3821 - val_dense_3_loss: 0.4491 - val_dense_2_root_mean_squared_error: 0.6181 - val_dense_3_root_mean_squared_error: 0.6702\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3524 - dense_2_loss: 0.3441 - dense_3_loss: 0.4270 - dense_2_root_mean_squared_error: 0.5866 - dense_3_root_mean_squared_error: 0.6535 - val_loss: 0.3305 - val_dense_2_loss: 0.3209 - val_dense_3_loss: 0.4172 - val_dense_2_root_mean_squared_error: 0.5665 - val_dense_3_root_mean_squared_error: 0.6459\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3471 - dense_2_loss: 0.3388 - dense_3_loss: 0.4215 - dense_2_root_mean_squared_error: 0.5821 - dense_3_root_mean_squared_error: 0.6492 - val_loss: 0.6191 - val_dense_2_loss: 0.6090 - val_dense_3_loss: 0.7101 - val_dense_2_root_mean_squared_error: 0.7804 - val_dense_3_root_mean_squared_error: 0.8427\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3478 - dense_2_loss: 0.3405 - dense_3_loss: 0.4136 - dense_2_root_mean_squared_error: 0.5835 - dense_3_root_mean_squared_error: 0.6431 - val_loss: 0.4757 - val_dense_2_loss: 0.4655 - val_dense_3_loss: 0.5676 - val_dense_2_root_mean_squared_error: 0.6823 - val_dense_3_root_mean_squared_error: 0.7534\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3426 - dense_2_loss: 0.3353 - dense_3_loss: 0.4082 - dense_2_root_mean_squared_error: 0.5791 - dense_3_root_mean_squared_error: 0.6389 - val_loss: 1.2899 - val_dense_2_loss: 1.2851 - val_dense_3_loss: 1.3328 - val_dense_2_root_mean_squared_error: 1.1336 - val_dense_3_root_mean_squared_error: 1.1545\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3471 - dense_2_loss: 0.3401 - dense_3_loss: 0.4101 - dense_2_root_mean_squared_error: 0.5832 - dense_3_root_mean_squared_error: 0.6404 - val_loss: 1.6734 - val_dense_2_loss: 1.6828 - val_dense_3_loss: 1.5894 - val_dense_2_root_mean_squared_error: 1.2972 - val_dense_3_root_mean_squared_error: 1.2607\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3470 - dense_2_loss: 0.3402 - dense_3_loss: 0.4084 - dense_2_root_mean_squared_error: 0.5832 - dense_3_root_mean_squared_error: 0.6391 - val_loss: 1.1047 - val_dense_2_loss: 1.1171 - val_dense_3_loss: 0.9933 - val_dense_2_root_mean_squared_error: 1.0569 - val_dense_3_root_mean_squared_error: 0.9967\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3415 - dense_2_loss: 0.3351 - dense_3_loss: 0.3986 - dense_2_root_mean_squared_error: 0.5789 - dense_3_root_mean_squared_error: 0.6313 - val_loss: 0.8908 - val_dense_2_loss: 0.9164 - val_dense_3_loss: 0.6600 - val_dense_2_root_mean_squared_error: 0.9573 - val_dense_3_root_mean_squared_error: 0.8124\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3428 - dense_2_loss: 0.3365 - dense_3_loss: 0.3993 - dense_2_root_mean_squared_error: 0.5801 - dense_3_root_mean_squared_error: 0.6319 - val_loss: 0.6072 - val_dense_2_loss: 0.6130 - val_dense_3_loss: 0.5557 - val_dense_2_root_mean_squared_error: 0.7829 - val_dense_3_root_mean_squared_error: 0.7455\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_wide = tf.keras.layers.Input(shape=[5])  # features 0 to 4\n",
    "input_deep = tf.keras.layers.Input(shape=[6])  # features 2 to 7\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "norm_wide = norm_layer_wide(input_wide)\n",
    "norm_deep = norm_layer_deep(input_deep)\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "aux_output = tf.keras.layers.Dense(1)(hidden2)\n",
    "model = tf.keras.Model(inputs=[input_wide, input_deep],\n",
    "                       outputs=[output, aux_output])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=(\"mse\", \"mse\"), loss_weights=(0.9, 0.1), optimizer=optimizer,\n",
    "              metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "norm_layer_wide.adapt(X_train_wide)\n",
    "norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=20,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you evaluate the model, Keras returns the weighted sum of the\n",
    "losses, as well as all the individual losses and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3342 - dense_2_loss: 0.3276 - dense_3_loss: 0.3933 - dense_2_root_mean_squared_error: 0.5724 - dense_3_root_mean_squared_error: 0.6272\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000201BCC47940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 287ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wideAndDeepModel(tf.keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # needed to support naming the model\n",
    "        self.norm_layer_wide = tf.keras.layers.Normalization()\n",
    "        self.norm_layer_deep = tf.keras.layers.Normalization()\n",
    "        self.hidden1 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = tf.keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = tf.keras.layers.Dense(1)\n",
    "        self.aux_output = tf.keras.layers.Dense(1)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs\n",
    "        norm_wide = self.norm_layer_wide(input_wide)\n",
    "        norm_deep = self.norm_layer_deep(input_deep)\n",
    "        hidden1 = self.hidden1(norm_deep)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "        output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return output, aux_output\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "model = wideAndDeepModel(30 , activation='relu', name='my_cool_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 1.5310 - output_1_loss: 1.4715 - output_2_loss: 2.0669 - output_1_root_mean_squared_error: 1.2130 - output_2_root_mean_squared_error: 1.4377 - val_loss: 1.5722 - val_output_1_loss: 1.2918 - val_output_2_loss: 4.0960 - val_output_1_root_mean_squared_error: 1.1366 - val_output_2_root_mean_squared_error: 2.0239\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.5741 - output_1_loss: 0.5501 - output_2_loss: 0.7899 - output_1_root_mean_squared_error: 0.7417 - output_2_root_mean_squared_error: 0.8888 - val_loss: 0.6589 - val_output_1_loss: 0.5244 - val_output_2_loss: 1.8692 - val_output_1_root_mean_squared_error: 0.7241 - val_output_2_root_mean_squared_error: 1.3672\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4719 - output_1_loss: 0.4579 - output_2_loss: 0.5985 - output_1_root_mean_squared_error: 0.6767 - output_2_root_mean_squared_error: 0.7736 - val_loss: 0.5397 - val_output_1_loss: 0.4749 - val_output_2_loss: 1.1227 - val_output_1_root_mean_squared_error: 0.6891 - val_output_2_root_mean_squared_error: 1.0596\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4369 - output_1_loss: 0.4236 - output_2_loss: 0.5565 - output_1_root_mean_squared_error: 0.6508 - output_2_root_mean_squared_error: 0.7460 - val_loss: 0.4561 - val_output_1_loss: 0.4456 - val_output_2_loss: 0.5506 - val_output_1_root_mean_squared_error: 0.6675 - val_output_2_root_mean_squared_error: 0.7420\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.4128 - output_1_loss: 0.4001 - output_2_loss: 0.5273 - output_1_root_mean_squared_error: 0.6325 - output_2_root_mean_squared_error: 0.7262 - val_loss: 0.4666 - val_output_1_loss: 0.4443 - val_output_2_loss: 0.6677 - val_output_1_root_mean_squared_error: 0.6666 - val_output_2_root_mean_squared_error: 0.8171\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3985 - output_1_loss: 0.3859 - output_2_loss: 0.5113 - output_1_root_mean_squared_error: 0.6212 - output_2_root_mean_squared_error: 0.7150 - val_loss: 0.3759 - val_output_1_loss: 0.3642 - val_output_2_loss: 0.4811 - val_output_1_root_mean_squared_error: 0.6035 - val_output_2_root_mean_squared_error: 0.6936\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3879 - output_1_loss: 0.3760 - output_2_loss: 0.4946 - output_1_root_mean_squared_error: 0.6132 - output_2_root_mean_squared_error: 0.7033 - val_loss: 0.4477 - val_output_1_loss: 0.4330 - val_output_2_loss: 0.5804 - val_output_1_root_mean_squared_error: 0.6580 - val_output_2_root_mean_squared_error: 0.7618\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3815 - output_1_loss: 0.3704 - output_2_loss: 0.4823 - output_1_root_mean_squared_error: 0.6086 - output_2_root_mean_squared_error: 0.6945 - val_loss: 0.7985 - val_output_1_loss: 0.8308 - val_output_2_loss: 0.5078 - val_output_1_root_mean_squared_error: 0.9115 - val_output_2_root_mean_squared_error: 0.7126\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3761 - output_1_loss: 0.3655 - output_2_loss: 0.4719 - output_1_root_mean_squared_error: 0.6045 - output_2_root_mean_squared_error: 0.6870 - val_loss: 2.2039 - val_output_1_loss: 2.2280 - val_output_2_loss: 1.9865 - val_output_1_root_mean_squared_error: 1.4927 - val_output_2_root_mean_squared_error: 1.4094\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3891 - output_1_loss: 0.3797 - output_2_loss: 0.4739 - output_1_root_mean_squared_error: 0.6162 - output_2_root_mean_squared_error: 0.6884 - val_loss: 1.1158 - val_output_1_loss: 1.1404 - val_output_2_loss: 0.8943 - val_output_1_root_mean_squared_error: 1.0679 - val_output_2_root_mean_squared_error: 0.9457\n",
      "162/162 [==============================] - 1s 4ms/step - loss: 0.3678 - output_1_loss: 0.3591 - output_2_loss: 0.4463 - output_1_root_mean_squared_error: 0.5993 - output_2_root_mean_squared_error: 0.6681\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002019C60D160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 289ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', loss_weights=[.9, .1], optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), metrics=['RootMeanSquaredError'])\n",
    "model.norm_layer_wide.adapt(X_train_wide)\n",
    "model.norm_layer_deep.adapt(X_train_deep)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)))\n",
    "eval_results = model.evaluate((X_test_wide, X_test_deep), (y_test, y_test))\n",
    "weighted_sum_of_losses, main_loss, aux_loss, main_rmse, aux_rmse = eval_results\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_keras_model\\assets\n",
      "my_keras_model\\assets\n",
      "my_keras_model\\keras_metadata.pb\n",
      "my_keras_model\\saved_model.pb\n",
      "my_keras_model\\variables\n",
      "my_keras_model\\variables\\variables.data-00000-of-00001\n",
      "my_keras_model\\variables\\variables.index\n",
      "1/1 [==============================] - 0s 328ms/step\n",
      "my_weights.data-00000-of-00001\n",
      "my_weights.index\n"
     ]
    }
   ],
   "source": [
    "# extra code – delete the directory, in case it already exists\n",
    "\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"my_keras_model\", ignore_errors=True)\n",
    "\n",
    "\n",
    "model.save(\"my_keras_model\")\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# extra code – show the contents of the my_keras_model/ directory\n",
    "for path in sorted(Path(\"my_keras_model\").glob(\"**/*\")):\n",
    "    print(path)\n",
    "\n",
    "model = tf.keras.models.load_model(\"my_keras_model\")\n",
    "y_pred_main, y_pred_aux = model.predict((X_new_wide, X_new_deep))\n",
    "\n",
    "model.save_weights(\"my_weights\")\n",
    "\n",
    "model.load_weights(\"my_weights\")\n",
    "\n",
    "# extra code – show the list of my_weights.* files\n",
    "for path in sorted(Path().glob(\"my_weights.*\")):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(\"my_checkpoints\", ignore_errors=True)  # extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 4s 6ms/step - loss: 0.3652 - output_1_loss: 0.3555 - output_2_loss: 0.4526 - output_1_root_mean_squared_error: 0.5962 - output_2_root_mean_squared_error: 0.6728 - val_loss: 0.6096 - val_output_1_loss: 0.6019 - val_output_2_loss: 0.6791 - val_output_1_root_mean_squared_error: 0.7758 - val_output_2_root_mean_squared_error: 0.8241\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3703 - output_1_loss: 0.3614 - output_2_loss: 0.4502 - output_1_root_mean_squared_error: 0.6011 - output_2_root_mean_squared_error: 0.6710 - val_loss: 0.5310 - val_output_1_loss: 0.5379 - val_output_2_loss: 0.4693 - val_output_1_root_mean_squared_error: 0.7334 - val_output_2_root_mean_squared_error: 0.6851\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3595 - output_1_loss: 0.3510 - output_2_loss: 0.4357 - output_1_root_mean_squared_error: 0.5925 - output_2_root_mean_squared_error: 0.6601 - val_loss: 1.3756 - val_output_1_loss: 1.3745 - val_output_2_loss: 1.3854 - val_output_1_root_mean_squared_error: 1.1724 - val_output_2_root_mean_squared_error: 1.1770\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3615 - output_1_loss: 0.3531 - output_2_loss: 0.4377 - output_1_root_mean_squared_error: 0.5942 - output_2_root_mean_squared_error: 0.6616 - val_loss: 1.3729 - val_output_1_loss: 1.4426 - val_output_2_loss: 0.7455 - val_output_1_root_mean_squared_error: 1.2011 - val_output_2_root_mean_squared_error: 0.8634\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3595 - output_1_loss: 0.3519 - output_2_loss: 0.4279 - output_1_root_mean_squared_error: 0.5932 - output_2_root_mean_squared_error: 0.6541 - val_loss: 1.8440 - val_output_1_loss: 1.6733 - val_output_2_loss: 3.3800 - val_output_1_root_mean_squared_error: 1.2936 - val_output_2_root_mean_squared_error: 1.8385\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3613 - output_1_loss: 0.3522 - output_2_loss: 0.4426 - output_1_root_mean_squared_error: 0.5935 - output_2_root_mean_squared_error: 0.6653 - val_loss: 0.8581 - val_output_1_loss: 0.8439 - val_output_2_loss: 0.9854 - val_output_1_root_mean_squared_error: 0.9186 - val_output_2_root_mean_squared_error: 0.9927\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3509 - output_1_loss: 0.3429 - output_2_loss: 0.4229 - output_1_root_mean_squared_error: 0.5856 - output_2_root_mean_squared_error: 0.6503 - val_loss: 0.5987 - val_output_1_loss: 0.5647 - val_output_2_loss: 0.9050 - val_output_1_root_mean_squared_error: 0.7515 - val_output_2_root_mean_squared_error: 0.9513\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3467 - output_1_loss: 0.3391 - output_2_loss: 0.4151 - output_1_root_mean_squared_error: 0.5823 - output_2_root_mean_squared_error: 0.6443 - val_loss: 0.7390 - val_output_1_loss: 0.7518 - val_output_2_loss: 0.6244 - val_output_1_root_mean_squared_error: 0.8671 - val_output_2_root_mean_squared_error: 0.7902\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3462 - output_1_loss: 0.3387 - output_2_loss: 0.4133 - output_1_root_mean_squared_error: 0.5820 - output_2_root_mean_squared_error: 0.6429 - val_loss: 1.2337 - val_output_1_loss: 1.1344 - val_output_2_loss: 2.1277 - val_output_1_root_mean_squared_error: 1.0651 - val_output_2_root_mean_squared_error: 1.4587\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3544 - output_1_loss: 0.3469 - output_2_loss: 0.4218 - output_1_root_mean_squared_error: 0.5890 - output_2_root_mean_squared_error: 0.6494 - val_loss: 0.6157 - val_output_1_loss: 0.6078 - val_output_2_loss: 0.6866 - val_output_1_root_mean_squared_error: 0.7796 - val_output_2_root_mean_squared_error: 0.8286\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('my_checkpoints', save_weights_only=True)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3428 - output_1_loss: 0.3353 - output_2_loss: 0.4108 - output_1_root_mean_squared_error: 0.5790 - output_2_root_mean_squared_error: 0.6409 - val_loss: 1.0504 - val_output_1_loss: 1.0372 - val_output_2_loss: 1.1691 - val_output_1_root_mean_squared_error: 1.0184 - val_output_2_root_mean_squared_error: 1.0813\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3481 - output_1_loss: 0.3415 - output_2_loss: 0.4078 - output_1_root_mean_squared_error: 0.5844 - output_2_root_mean_squared_error: 0.6386 - val_loss: 0.8522 - val_output_1_loss: 0.8991 - val_output_2_loss: 0.4299 - val_output_1_root_mean_squared_error: 0.9482 - val_output_2_root_mean_squared_error: 0.6557\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3430 - output_1_loss: 0.3366 - output_2_loss: 0.4011 - output_1_root_mean_squared_error: 0.5801 - output_2_root_mean_squared_error: 0.6333 - val_loss: 1.0904 - val_output_1_loss: 1.0987 - val_output_2_loss: 1.0160 - val_output_1_root_mean_squared_error: 1.0482 - val_output_2_root_mean_squared_error: 1.0080\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3417 - output_1_loss: 0.3350 - output_2_loss: 0.4019 - output_1_root_mean_squared_error: 0.5788 - output_2_root_mean_squared_error: 0.6339 - val_loss: 0.6882 - val_output_1_loss: 0.7089 - val_output_2_loss: 0.5023 - val_output_1_root_mean_squared_error: 0.8420 - val_output_2_root_mean_squared_error: 0.7088\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3406 - output_1_loss: 0.3341 - output_2_loss: 0.3985 - output_1_root_mean_squared_error: 0.5780 - output_2_root_mean_squared_error: 0.6313 - val_loss: 0.8886 - val_output_1_loss: 0.8032 - val_output_2_loss: 1.6578 - val_output_1_root_mean_squared_error: 0.8962 - val_output_2_root_mean_squared_error: 1.2875\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3363 - output_1_loss: 0.3293 - output_2_loss: 0.3997 - output_1_root_mean_squared_error: 0.5738 - output_2_root_mean_squared_error: 0.6322 - val_loss: 0.5324 - val_output_1_loss: 0.5388 - val_output_2_loss: 0.4749 - val_output_1_root_mean_squared_error: 0.7340 - val_output_2_root_mean_squared_error: 0.6892\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3358 - output_1_loss: 0.3293 - output_2_loss: 0.3946 - output_1_root_mean_squared_error: 0.5738 - output_2_root_mean_squared_error: 0.6282 - val_loss: 0.6103 - val_output_1_loss: 0.5643 - val_output_2_loss: 1.0247 - val_output_1_root_mean_squared_error: 0.7512 - val_output_2_root_mean_squared_error: 1.0123\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3322 - output_1_loss: 0.3257 - output_2_loss: 0.3913 - output_1_root_mean_squared_error: 0.5707 - output_2_root_mean_squared_error: 0.6256 - val_loss: 0.5525 - val_output_1_loss: 0.5562 - val_output_2_loss: 0.5188 - val_output_1_root_mean_squared_error: 0.7458 - val_output_2_root_mean_squared_error: 0.7203\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3316 - output_1_loss: 0.3251 - output_2_loss: 0.3899 - output_1_root_mean_squared_error: 0.5702 - output_2_root_mean_squared_error: 0.6245 - val_loss: 1.2120 - val_output_1_loss: 1.1173 - val_output_2_loss: 2.0650 - val_output_1_root_mean_squared_error: 1.0570 - val_output_2_root_mean_squared_error: 1.4370\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3386 - output_1_loss: 0.3320 - output_2_loss: 0.3975 - output_1_root_mean_squared_error: 0.5762 - output_2_root_mean_squared_error: 0.6305 - val_loss: 0.5538 - val_output_1_loss: 0.5551 - val_output_2_loss: 0.5413 - val_output_1_root_mean_squared_error: 0.7451 - val_output_2_root_mean_squared_error: 0.7357\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3286 - output_1_loss: 0.3222 - output_2_loss: 0.3862 - output_1_root_mean_squared_error: 0.5676 - output_2_root_mean_squared_error: 0.6215 - val_loss: 0.4973 - val_output_1_loss: 0.4714 - val_output_2_loss: 0.7311 - val_output_1_root_mean_squared_error: 0.6866 - val_output_2_root_mean_squared_error: 0.8550\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3330 - output_1_loss: 0.3269 - output_2_loss: 0.3884 - output_1_root_mean_squared_error: 0.5717 - output_2_root_mean_squared_error: 0.6232 - val_loss: 0.3466 - val_output_1_loss: 0.3433 - val_output_2_loss: 0.3768 - val_output_1_root_mean_squared_error: 0.5859 - val_output_2_root_mean_squared_error: 0.6139\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3271 - output_1_loss: 0.3210 - output_2_loss: 0.3826 - output_1_root_mean_squared_error: 0.5665 - output_2_root_mean_squared_error: 0.6185 - val_loss: 0.3958 - val_output_1_loss: 0.3671 - val_output_2_loss: 0.6539 - val_output_1_root_mean_squared_error: 0.6059 - val_output_2_root_mean_squared_error: 0.8086\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 3s 9ms/step - loss: 0.3256 - output_1_loss: 0.3192 - output_2_loss: 0.3828 - output_1_root_mean_squared_error: 0.5650 - output_2_root_mean_squared_error: 0.6187 - val_loss: 0.4835 - val_output_1_loss: 0.4752 - val_output_2_loss: 0.5580 - val_output_1_root_mean_squared_error: 0.6894 - val_output_2_root_mean_squared_error: 0.7470\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3273 - output_1_loss: 0.3211 - output_2_loss: 0.3833 - output_1_root_mean_squared_error: 0.5667 - output_2_root_mean_squared_error: 0.6191 - val_loss: 0.9795 - val_output_1_loss: 0.9385 - val_output_2_loss: 1.3482 - val_output_1_root_mean_squared_error: 0.9688 - val_output_2_root_mean_squared_error: 1.1611\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3287 - output_1_loss: 0.3226 - output_2_loss: 0.3830 - output_1_root_mean_squared_error: 0.5680 - output_2_root_mean_squared_error: 0.6189 - val_loss: 0.8077 - val_output_1_loss: 0.8157 - val_output_2_loss: 0.7362 - val_output_1_root_mean_squared_error: 0.9031 - val_output_2_root_mean_squared_error: 0.8580\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3302 - output_1_loss: 0.3240 - output_2_loss: 0.3856 - output_1_root_mean_squared_error: 0.5692 - output_2_root_mean_squared_error: 0.6210 - val_loss: 0.7574 - val_output_1_loss: 0.6958 - val_output_2_loss: 1.3117 - val_output_1_root_mean_squared_error: 0.8342 - val_output_2_root_mean_squared_error: 1.1453\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3233 - output_1_loss: 0.3171 - output_2_loss: 0.3789 - output_1_root_mean_squared_error: 0.5631 - output_2_root_mean_squared_error: 0.6156 - val_loss: 0.3837 - val_output_1_loss: 0.3831 - val_output_2_loss: 0.3896 - val_output_1_root_mean_squared_error: 0.6189 - val_output_2_root_mean_squared_error: 0.6242\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3195 - output_1_loss: 0.3137 - output_2_loss: 0.3722 - output_1_root_mean_squared_error: 0.5601 - output_2_root_mean_squared_error: 0.6101 - val_loss: 0.4189 - val_output_1_loss: 0.4154 - val_output_2_loss: 0.4499 - val_output_1_root_mean_squared_error: 0.6445 - val_output_2_root_mean_squared_error: 0.6707\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3204 - output_1_loss: 0.3146 - output_2_loss: 0.3723 - output_1_root_mean_squared_error: 0.5609 - output_2_root_mean_squared_error: 0.6102 - val_loss: 0.3372 - val_output_1_loss: 0.3336 - val_output_2_loss: 0.3696 - val_output_1_root_mean_squared_error: 0.5776 - val_output_2_root_mean_squared_error: 0.6079\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3194 - output_1_loss: 0.3138 - output_2_loss: 0.3697 - output_1_root_mean_squared_error: 0.5602 - output_2_root_mean_squared_error: 0.6080 - val_loss: 0.4142 - val_output_1_loss: 0.4089 - val_output_2_loss: 0.4616 - val_output_1_root_mean_squared_error: 0.6395 - val_output_2_root_mean_squared_error: 0.6794\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3188 - output_1_loss: 0.3131 - output_2_loss: 0.3694 - output_1_root_mean_squared_error: 0.5596 - output_2_root_mean_squared_error: 0.6078 - val_loss: 0.5932 - val_output_1_loss: 0.5954 - val_output_2_loss: 0.5740 - val_output_1_root_mean_squared_error: 0.7716 - val_output_2_root_mean_squared_error: 0.7577\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3156 - output_1_loss: 0.3100 - output_2_loss: 0.3662 - output_1_root_mean_squared_error: 0.5568 - output_2_root_mean_squared_error: 0.6051 - val_loss: 0.3045 - val_output_1_loss: 0.2985 - val_output_2_loss: 0.3579 - val_output_1_root_mean_squared_error: 0.5464 - val_output_2_root_mean_squared_error: 0.5983\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3198 - output_1_loss: 0.3143 - output_2_loss: 0.3690 - output_1_root_mean_squared_error: 0.5606 - output_2_root_mean_squared_error: 0.6074 - val_loss: 0.7297 - val_output_1_loss: 0.7395 - val_output_2_loss: 0.6416 - val_output_1_root_mean_squared_error: 0.8599 - val_output_2_root_mean_squared_error: 0.8010\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3189 - output_1_loss: 0.3134 - output_2_loss: 0.3683 - output_1_root_mean_squared_error: 0.5598 - output_2_root_mean_squared_error: 0.6069 - val_loss: 0.5728 - val_output_1_loss: 0.5655 - val_output_2_loss: 0.6380 - val_output_1_root_mean_squared_error: 0.7520 - val_output_2_root_mean_squared_error: 0.7988\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3167 - output_1_loss: 0.3112 - output_2_loss: 0.3659 - output_1_root_mean_squared_error: 0.5579 - output_2_root_mean_squared_error: 0.6049 - val_loss: 0.3233 - val_output_1_loss: 0.3194 - val_output_2_loss: 0.3588 - val_output_1_root_mean_squared_error: 0.5651 - val_output_2_root_mean_squared_error: 0.5990\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3135 - output_1_loss: 0.3082 - output_2_loss: 0.3619 - output_1_root_mean_squared_error: 0.5551 - output_2_root_mean_squared_error: 0.6016 - val_loss: 0.3579 - val_output_1_loss: 0.3462 - val_output_2_loss: 0.4633 - val_output_1_root_mean_squared_error: 0.5884 - val_output_2_root_mean_squared_error: 0.6806\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3136 - output_1_loss: 0.3082 - output_2_loss: 0.3623 - output_1_root_mean_squared_error: 0.5551 - output_2_root_mean_squared_error: 0.6019 - val_loss: 0.3318 - val_output_1_loss: 0.3289 - val_output_2_loss: 0.3577 - val_output_1_root_mean_squared_error: 0.5735 - val_output_2_root_mean_squared_error: 0.5981\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3113 - output_1_loss: 0.3058 - output_2_loss: 0.3606 - output_1_root_mean_squared_error: 0.5530 - output_2_root_mean_squared_error: 0.6005 - val_loss: 0.3903 - val_output_1_loss: 0.3861 - val_output_2_loss: 0.4282 - val_output_1_root_mean_squared_error: 0.6214 - val_output_2_root_mean_squared_error: 0.6544\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3105 - output_1_loss: 0.3052 - output_2_loss: 0.3578 - output_1_root_mean_squared_error: 0.5525 - output_2_root_mean_squared_error: 0.5981 - val_loss: 0.3023 - val_output_1_loss: 0.2949 - val_output_2_loss: 0.3689 - val_output_1_root_mean_squared_error: 0.5431 - val_output_2_root_mean_squared_error: 0.6074\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3146 - output_1_loss: 0.3095 - output_2_loss: 0.3607 - output_1_root_mean_squared_error: 0.5563 - output_2_root_mean_squared_error: 0.6005 - val_loss: 0.3371 - val_output_1_loss: 0.3298 - val_output_2_loss: 0.4031 - val_output_1_root_mean_squared_error: 0.5742 - val_output_2_root_mean_squared_error: 0.6349\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3105 - output_1_loss: 0.3053 - output_2_loss: 0.3568 - output_1_root_mean_squared_error: 0.5526 - output_2_root_mean_squared_error: 0.5973 - val_loss: 0.3062 - val_output_1_loss: 0.2999 - val_output_2_loss: 0.3634 - val_output_1_root_mean_squared_error: 0.5476 - val_output_2_root_mean_squared_error: 0.6029\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3084 - output_1_loss: 0.3031 - output_2_loss: 0.3557 - output_1_root_mean_squared_error: 0.5506 - output_2_root_mean_squared_error: 0.5964 - val_loss: 0.4243 - val_output_1_loss: 0.4207 - val_output_2_loss: 0.4569 - val_output_1_root_mean_squared_error: 0.6486 - val_output_2_root_mean_squared_error: 0.6759\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3077 - output_1_loss: 0.3027 - output_2_loss: 0.3530 - output_1_root_mean_squared_error: 0.5502 - output_2_root_mean_squared_error: 0.5941 - val_loss: 0.7755 - val_output_1_loss: 0.8050 - val_output_2_loss: 0.5099 - val_output_1_root_mean_squared_error: 0.8972 - val_output_2_root_mean_squared_error: 0.7140\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3123 - output_1_loss: 0.3074 - output_2_loss: 0.3563 - output_1_root_mean_squared_error: 0.5545 - output_2_root_mean_squared_error: 0.5969 - val_loss: 0.8188 - val_output_1_loss: 0.7916 - val_output_2_loss: 1.0640 - val_output_1_root_mean_squared_error: 0.8897 - val_output_2_root_mean_squared_error: 1.0315\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3110 - output_1_loss: 0.3056 - output_2_loss: 0.3593 - output_1_root_mean_squared_error: 0.5528 - output_2_root_mean_squared_error: 0.5994 - val_loss: 0.7249 - val_output_1_loss: 0.6979 - val_output_2_loss: 0.9677 - val_output_1_root_mean_squared_error: 0.8354 - val_output_2_root_mean_squared_error: 0.9837\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3099 - output_1_loss: 0.3046 - output_2_loss: 0.3582 - output_1_root_mean_squared_error: 0.5519 - output_2_root_mean_squared_error: 0.5985 - val_loss: 0.6647 - val_output_1_loss: 0.6957 - val_output_2_loss: 0.3856 - val_output_1_root_mean_squared_error: 0.8341 - val_output_2_root_mean_squared_error: 0.6210\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.3065 - output_1_loss: 0.3015 - output_2_loss: 0.3510 - output_1_root_mean_squared_error: 0.5491 - output_2_root_mean_squared_error: 0.5925 - val_loss: 0.3943 - val_output_1_loss: 0.3975 - val_output_2_loss: 0.3659 - val_output_1_root_mean_squared_error: 0.6305 - val_output_2_root_mean_squared_error: 0.6049\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3063 - output_1_loss: 0.3013 - output_2_loss: 0.3517 - output_1_root_mean_squared_error: 0.5489 - output_2_root_mean_squared_error: 0.5930 - val_loss: 0.3571 - val_output_1_loss: 0.3490 - val_output_2_loss: 0.4296 - val_output_1_root_mean_squared_error: 0.5908 - val_output_2_root_mean_squared_error: 0.6554\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 3s 8ms/step - loss: 0.3020 - output_1_loss: 0.2970 - output_2_loss: 0.3468 - output_1_root_mean_squared_error: 0.5450 - output_2_root_mean_squared_error: 0.5889 - val_loss: 0.3292 - val_output_1_loss: 0.3255 - val_output_2_loss: 0.3626 - val_output_1_root_mean_squared_error: 0.5705 - val_output_2_root_mean_squared_error: 0.6021\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=100,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        ratio = logs['val_loss'] / logs['loss']\n",
    "        print(f\"Epoch={epoch} val/train={ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0 val/train=1.05\n",
      "Epoch=1 val/train=1.02\n",
      "Epoch=2 val/train=1.06\n",
      "Epoch=3 val/train=1.70\n",
      "Epoch=4 val/train=1.63\n",
      "Epoch=5 val/train=1.97\n",
      "Epoch=6 val/train=3.32\n",
      "Epoch=7 val/train=1.72\n",
      "Epoch=8 val/train=1.79\n",
      "Epoch=9 val/train=0.96\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(\n",
    "    (X_train_wide, X_train_deep), (y_train, y_train), epochs=10,\n",
    "    validation_data=((X_valid_wide, X_valid_deep), (y_valid, y_valid)),\n",
    "    callbacks=[val_train_ratio_cb], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_minst\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of the function defines the hyperparameters. For example,\n",
    "`hp.Int(\"n_hidden\", min_value=0, max_value=8,\n",
    "default=2)` checks whether a hyperparameter named \"n_hidden\" is\n",
    "already present in the HyperParameters object hp, and if so it returns\n",
    "its value.  \n",
    "If not, then it registers a new integer hyperparameter named\n",
    "\"n_hidden\", whose possible values range from 0 to 8 (inclusive), and it\n",
    "returns the default value, which is 2 in this case (when default is not set,\n",
    "then min_value is returned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int('n_hidden', min_value=0, max_value=8, default=2)\n",
    "    n_neurons = hp.Int('n_nuerons', min_value=16, max_value=256)\n",
    "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    optimizer = hp.Choice('optimizer', values=['sgd', 'adam'])\n",
    "    if optimizer == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 01m 30s]\n",
      "val_accuracy: 0.8754000067710876\n",
      "\n",
      "Best val_accuracy So Far: 0.8754000067710876\n",
      "Total elapsed time: 00h 08m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "random_search_tuner = kt.RandomSearch(build_model, objective='val_accuracy', max_trials=5, overwrite=True,\n",
    "    directory=\"my_fashion_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "random_search_tuner.search(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'm' for (root).layer_with_weights-5.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-1.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.kernel\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer's state 'v' for (root).layer_with_weights-5.bias\n"
     ]
    }
   ],
   "source": [
    "top3_models = random_search_tuner.get_best_models(num_models=3)\n",
    "best_model = top3_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 5\n",
      "n_nuerons: 70\n",
      "learning_rate: 0.00041268008323824807\n",
      "optimizer: adam\n",
      "Score: 0.8754000067710876\n"
     ]
    }
   ],
   "source": [
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8754000067710876"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3212 - accuracy: 0.8829\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3076 - accuracy: 0.8871\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3012 - accuracy: 0.8896\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2896 - accuracy: 0.8931\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2846 - accuracy: 0.8953\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2751 - accuracy: 0.8982\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2704 - accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2644 - accuracy: 0.9021\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2574 - accuracy: 0.9040\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2562 - accuracy: 0.9042\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8767\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train_full, y_train_full, epochs=10)\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune data preprocessing\n",
    "hyperparameters, or\n",
    "`model.fit()`\n",
    "arguments, such as the batch size.  \n",
    "you must subclass the\n",
    "`kt.HyperModel`\n",
    "class and define two methods,\n",
    "`build()`\n",
    "and\n",
    "`fit()`.  \n",
    "The\n",
    "`build()`\n",
    "method does the exact same thing as the\n",
    "`build_model()`\n",
    "function.  \n",
    "he\n",
    "`fit()`\n",
    "method may use hyperparameters to decide how to preprocess the data,\n",
    "tweak the batch size, and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyClassificationHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        return build_model(hp)\n",
    "\n",
    "    def fit(self, hp,  model, X, y, **kwargs):\n",
    "        if hp.Boolean('normalize'):\n",
    "            X = tf.keras.layers.Normalization()(X)\n",
    "        return model.fit(X, y, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperband_tuner = kt.Hyperband(MyClassificationHyperModel(), objective='val_accuracy', seed=42,\n",
    "            max_epochs=10, factor=3, hyperband_iterations=2,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"hyperband\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 01m 23s]\n",
      "val_accuracy: 0.8529999852180481\n",
      "\n",
      "Best val_accuracy So Far: 0.8708000183105469\n",
      "Total elapsed time: 00h 44m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "root_logdir = Path(hyperband_tuner.project_dir) / \"tensorboard\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(root_logdir)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "hyperband_tuner.search(X_train, y_train, epochs=10,\n",
    "                       validation_data=(X_valid, y_valid),\n",
    "                       callbacks=[early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 33s]\n",
      "val_accuracy: 0.8076000213623047\n",
      "\n",
      "Best val_accuracy So Far: 0.8628000020980835\n",
      "Total elapsed time: 00h 13m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "bayesian_opt_tuner = kt.BayesianOptimization(\n",
    "    MyClassificationHyperModel(), objective=\"val_accuracy\", seed=42,\n",
    "    max_trials=10, alpha=1e-4, beta=2.6,\n",
    "    overwrite=True, directory=\"my_fashion_mnist\", project_name=\"bayesian_opt\")\n",
    "bayesian_opt_tuner.search(X_train, y_train, epochs=10,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=[early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32ea8bee040c0262fda3837df9bb0dbef9f2bbaf3c67025b7197e1c5d673cff9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
